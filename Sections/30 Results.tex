\section{Findings}
\label{sec:Results}
The systematic search was conducted on October 4, 2022. An overview of the literature review, including each step of the process, is shown in \autoref{fig:PRISMA-flowchart}.

\todo[inline]{Move PRISMA to end of method, rather than results.}
% Number of papers per stage, results from the methodology
\begin{figure}[p]
    \centering
    \import{./Images/}{PRISMA-flowchart}
    \caption[Overview of literature review]{Overview of literature review. Adapted from \textcite{PRISMA_2022}.}
    \label{fig:PRISMA-flowchart}
\end{figure}


\subsection{Descriptive Results} % See Lukkien et al.
As shown in \autoref{fig:PRISMA-flowchart}, a total of 289 unique titles were assessed during the literature review. After filtering on titles, abstracts, and the full text, and after adding sources from snowballing, 54 documents were included in the review. An overview of the reviewed papers can be seen in \autoref{tab:paper-overview} (\autoref{app:overview}).

\autoref{tab:summary-year} shows the yearly distribution of the assessed papers, for each step of the literature review. The oldest of the assessed papers was published in 2015, with the majority of publications happening in 2019-2022 ($n = 279$; 97\%). The same distribution is reflected in the reviewed papers, where the oldest paper was published in 2017, and 94\% of the papers ($n = 50$) were published between 2019-2022. This indicates a young field of science, that has just recently gained traction. Although the field is still young, discussions with my supervisor led to the conclusion that 289 unique results in the preliminary search means the field has been explored enough to conduct a systematic literature review.

\begin{table}[!ht]
    \centering
    \caption{Yearly distribution of the assessed papers.}
    \label{tab:summary-year}
    \begin{threeparttable}
    \begin{tabular}{lcccc}
    \toprule
        \multirow{2}{*}{\textbf{Year}}
            & \multirow{2}{*}{\textbf{Raw data}}
            & \multirow{2}{*}{\shortstack{\textbf{After title}\\\textbf{filtering}}}
            & \multirow{2}{*}{\shortstack{\textbf{After abstract}\\\textbf{filtering}}}
            & \multirow{2}{*}{\textbf{Review}} \\ \\
    \midrule
        \textbf{2015} & 1 & 0 & 0 & 0 \\ 
        \textbf{2016} & 1 & 0 & 0 & 0 \\ 
        \textbf{2017} & 0 & 0 & 0 & 1 \\ 
        \textbf{2018} & 2 & 2 & 1 & 3 \\ 
        \textbf{2019} & 16 & 14 & 3 & 8 \\ 
        \textbf{2020} & 45 & 34 & 9 & 10 \\ 
        \textbf{2021} & 113 & 80 & 24 & 17 \\ 
        \textbf{2022} & 105 & 83 & 20 & 15 \\ 
        \textbf{2023} & 1 & 1 & 0 & 0 \\ 
        \textbf{No year}\tnote{*} & 5 & 3 & 0 & 0 \\ 
    \midrule
        \textbf{Total} & \textbf{289} & \textbf{217} & \textbf{57} & \textbf{54} \\ 
    \bottomrule
    \end{tabular}
    \begin{tablenotes}
        \footnotesize
        \item [*] No year provided in the databases.
    \end{tablenotes}
\end{threeparttable}
\end{table}

% Compare primary vs secondary studies
While the field is relatively young, the methodology used by researchers within the field, as shown in \autoref{tab:summary-methodology}, indicates a certain level of maturity. \textcite[p. 930]{Keathley-Herring_2016} states that \textquote{a research area should evolve from an exploratory beginning to conceptual frameworks being proposed and tested, and then to industry exposure and finally, a convergence on best practices and consistent terminology.} The papers included in the review employ a wide range of methodologies, of both an exploratory (reviews, expert discussions), conceptual (conceptual frameworks, viewpoints) and evaluative (qualitative interviews, quantitative surveys, case studies) nature. Some authors (e.g., \cite{Fjeld_2020,Jobin_2019}) have noted a convergence within the proposed principles as well, indicating that the field is approaching an agreed-upon set of best practices.

The fact that the research being done shows a high level of maturity while the actual field is young may be due to the connections between responsible AI and more established fields within AI- and software ethics. These connections are further explored in \autoref{sec:results-alernative-terms}.

\begin{table}[ht]
    \centering
    \caption{Methodologies used in the reviewed papers.}
    \label{tab:summary-methodology}
    \begin{threeparttable}
    \begin{tabular}{p{0.4\linewidth}cc}
    \toprule
        \textbf{Methodology} & \textbf{Count} & \textbf{Percentage}\tnote{*} \\
    \midrule
        Review of guidelines    & 9     & 17  \\
        Literature review       & 9     & 17  \\
        Qualitative interviews  & 9     & 17  \\
        Conceptual              & 7     & 13  \\
        Unknown                 & 6     & 11  \\
        Quantitative survey     & 5     & 9   \\
        Viewpoint               & 4     & 7   \\
        Case study              & 4     & 7   \\
        Expert discussion       & 3     & 6   \\
        Review of AI strategies & 2     & 4   \\
        Review of laws          & 1     & 2   \\
    \bottomrule
    \end{tabular}
    \begin{tablenotes}
        \footnotesize
        \item [*] Percentage of reviewed papers that use the methodology. Note that some papers use more than one methodology, so the percentages do not add up to 100.
    \end{tablenotes}
\end{threeparttable}
\end{table}

\autoref{tab:summary-context} shows the geographical context of the reviewed papers. Over half the papers ($n = 32$; 59\%) are created without a given context. This is relatively natural, as conceptual papers, viewpoints and literature reviews are rarely limited to geographical locations. All the reviewed papers are written in English, and the included literature reviews are also predominantly reviews of English papers. This creates a possibility for a Western bias, even in papers that appear to be written without a specific context.

For the rest of the papers, most are focused on a Western context ($n = 11$; 21\%), with some work being done in China ($n = 2$; 4\%), India ($n = 2$; 4\%) and South Africa ($n = 1$; 2\%). This geographical bias is reflected in the distribution of guideline documents that are available.
\todo{Possibly move this to discussion?}
\textcite{AlgorithmWatch} contains a set of 167 guidelines for developing responsible AI. While this is by no means an exhaustive list, the database has been in use since 2019 and is open for submissions \parencite{AlgorithmWatch_about}, making it a reliable source. Of the 167 guidelines in the database, only 14 (8\%) are from Asian countries, 1 (0.6\%) from Southern Africa and no guidelines come from South America or Northern Africa.

\begin{table}[htpb]
    \centering
    \caption{Geographical context of the reviewed papers.}
    \label{tab:summary-context}
    \begin{threeparttable}
    \begin{tabular}{p{0.4\linewidth}cc}
    \toprule
        \textbf{Location} & \textbf{Count} & \textbf{Percentage}\tnote{*} \\
    \midrule
        Europe                          & 8     & 15 \\ 
        Global                          & 6     & 11 \\ 
        The US                          & 2     & 4 \\
        China                           & 2     & 4 \\ 
        India                           & 2     & 4 \\ 
        Western countries in general    & 1     & 2 \\ 
        South Africa                    & 1     & 2 \\
        N/A\tnote{\textdagger}          & 32    & 59 \\ 
    \bottomrule
    \end{tabular}
    \begin{tablenotes}
        \footnotesize
        \item [*] Percentage of reviewed papers that focuses on the given location.
        \item [\textdagger] No context given. Includes viewpoints, conceptual papers, etc.
    \end{tablenotes}
\end{threeparttable}
\end{table}

As with geographical context, most of the reviewed papers ($n = 36$; 67\%) are written without a specific domain in mind. This is, once again, natural for conceptual papers, viewpoints and literature reviews, of which there are many among the reviewed papers. The rest of the papers are primarily focused on healthcare ($n = 7$; 13\%). Healthcare is a domain with a wide use of technological solutions (e.g. \cite{Azaria_2016,Martinez_2008,Son_2014}), including AI-based solutions (e.g. \cite{Singh_2023,Kumar_2023}). As health records are digitized \parencite{Rajkomar_2018}, yet more avenues for adopting AI opens up, with estimates valuing the data of NHS patients in the UK at around 10 billion GBP per year \parencite{Downey_2019}. At the same time, healthcare uses large amounts of personal data, thus increasing the sensitivity patients feel when interacting with systems, automatic or not \parencite{Gupta_2021}. Professionals in the field of healthcare are therefore used to ethical principles and guidelines, such as the Hippocratic Oath \parencite{Wiesing_2020}, and calls have been made to use medical ethics as a starting point for responsible AI guidelines \parencite{DaltonBrown_2020, Siala_2022}.

Outside of healthcare, papers tend to look at laws and governance ($n = 3$; 6\%) and AI developers ($n = 3$; 6\%). Both these cases are natural focus areas for responsible AI. As will be discussed in \autoref{sec:results-rq2:antecedents}, the primary antecedent for responsible AI is existing laws and regulations, with national AI strategies also working to push AI systems towards responsibility. Therefore, focusing on how laws and governance impacts -- and should impact -- the field of responsible AI is important, in order to ensure laws and strategies provide the best possible protection of laypersons, while limiting innovation as little as possible. In a similar fashion, the connection between responsible AI and AI developers is natural. Developers are those who actually design, create and maintain AI systems in use, and are therefore a natural source for understanding current practices in the industry, as well as which principles can be adopted, and how they should be adopted, in order to have the largest impact on moving AI in a responsible direction. A complete overview of the domains used in the reviewed papers can be seen in \autoref{tab:summary-domain}.

\begin{table}[htpb]
    \centering
    \caption{Domains of the reviewed papers.}
    \label{tab:summary-domain}
    \begin{threeparttable}
    \begin{tabular}{p{0.4\linewidth}cc}
    \toprule
        \textbf{Domain} & \textbf{Count} & \textbf{Percentage}\tnote{*} \\
    \midrule
        Healthcare              & 7     & 13 \\ 
        Laws and governance     & 3     & 6 \\
        Developers              & 3     & 6 \\
        Labor                   & 1     & 2 \\
        Education               & 1     & 2 \\
        Finance                 & 1     & 2 \\
        Water                   & 1     & 2 \\
        Multi-sector            & 1     & 2 \\
        N/A\tnote{\textdagger}  & 36    & 67 \\ 
    \bottomrule
    \end{tabular}
    \begin{tablenotes}
        \footnotesize
        \item [*] Percentage of reviewed papers that focuses on the given domain.
        \item [\textdagger] No domain given. Includes viewpoints, conceptual papers, etc.
    \end{tablenotes}
\end{threeparttable}
\end{table}

The reviewed papers come from a wide variety of sources, including journals from several different fields, books, and proceedings. An easy way to quickly assess the quality of a paper is by evaluating the rank of its journal or publisher \parencite{Keathley-Herring_2016}. In Norway, this is primarily done by the Norwegian Register for Scientific Journals, Series and Publishers, who uses a 3-level ranking system, with level 2 being the highest level, and 0 meaning that a journal was rejected from the register \parencite{kanalregisteret}. Using this register, \autoref{tab:summary-ranks} shows the ranks of the reviewed journals. No 0-ranked journals means that the papers can be considered good enough quality to use for a review.

\begin{table}[htpb]
    \centering
    \caption{Journal ranks of the reviewed papers.}
    \label{tab:summary-ranks}
    \begin{threeparttable}
    \begin{tabular}{p{0.4\linewidth}cc}
    \toprule
        \textbf{Journal rank} & \textbf{Count} & \textbf{Percentage}\tnote{*} \\
    \midrule
        2                       & 6     & 11    \\
        1                       & 34    & 63    \\
        0                       & 0     & 0     \\
        N/A\tnote{\textdagger}  & 14    & 26    \\
    \bottomrule
    \end{tabular}
    \begin{tablenotes}
        \footnotesize
        \item [*] Percentage of reviewed papers from a journal with the given rank.
        \item [\textdagger] Journal rank not available. Includes books, proceeding papers and journals that have not been evaluated by the Norwegian Register.
    \end{tablenotes}
\end{threeparttable}
\end{table}

% Mention non-peer-reviewed papers included in the review, and why they were included
Of the 54 papers used for this review, two are from sources that are not peer reviewed -- \textcite{Fjeld_2020} and \textcite{Floridi_2019}. Both these sources were gathered during snowballing, and are included for the same reason. \textcite{Fjeld_2020} compares 36 AI principles, and is considered \textquote{a landmark in the synthesis of AI ethics principles and guidance} \parencite[p. 2]{Bélisle-Pipon_2022}. Likewise, \textcite{Floridi_2019} reviewed six sets of principles, and supports the conclusions drawn by \textcite{Floridi_2018}. As the papers are central for the field, and referenced in multiple of the other papers, they were deemed relevant enough to be included in this review.

% Cite studies that might appear to meet the inclusion criteria, but which were excluded, and explain why they were excluded.
Some papers may appear to meet the inclusion criteria, but were still included. Examples of this include \textcite{ElHaddadeh_2021} and \textcite{Trocin_2021}. \textcite{ElHaddadeh_2021} presents an in-depth comparison of AI used for healthcare in the UK (NHS Test and Trace) and Quatar (EHTERAZ), looking at methods used for achieving responsibility in the two systems, and how well the systems performed at stopping the spread of COVID-19. Although the paper looks at ways AI can be used ethically, it neither defines responsible AI, contains or critizises a framework nor discusses antecedents or business advantages of responsible AI, and therefore does not answer the eligibility criteria. \textcite{Trocin_2021} performs a literature review aimed at ethical issues in healthcare, and how AI may help solve or mitigate these issues. While the topic of the article revolves around using AI ethically, its focus is primarily on ethical issues of healthcare, rather than ethical issues of AI, and the paper therefore does not answer the eligibility criteria. The rest of the papers rejected during full-text assessment (step 5, \autoref{sec:method-steps}) were rejected for similar reasons.


\subsection{Key concepts}
\todo[inline]{Remove own definitions, instead adopt from one of the reviewed papers (and defend it, argue why I am using that one)}
\todo[inline]{Remove block quotes (except for the quotes I am using in this text, where I \textit{can} keep them)}
\import{Sections/}{35 Definitions}


\subsection{RQ1 -- Principles for responsible AI}
\label{sec:results-rq1}
Of the 54 reviewed papers, 48 (89\%) present or use a set of principles to create or describe responsible AI, for a total of 58 unique principles. Three steps are used to make this set of principles more manageable. First, principles were clustered following the categorization done by \textcite{Ryan_2021}. Their work reviewed existing guidelines, and came up with 11 categories, containing 61 subcategories, which most of the reviewed principles aligned with. The principles that did not align with any subcategory were categorized with the closest fit, with principles that did not align with any clusters being grouped as \textit{Others}. This ensured all principles would be used in the review, without creating multiple low-density clusters.

After clustering the principles, some changes were made to the categories proposed by \textcite{Ryan_2021}. Clusters with fewer than five mentions among the reviewed texts were removed, and their principles moved to other clusters. This meant that \textit{Dignity} ($n = 3$) was moved to be part of \textit{Non-maleficence}, and \textit{Solidarity} ($n = 1$) became part of \textit{Justice and fairness}. As dignity can be considered to be a harm, and thus can be avoided by ensuring AI systems can do no harm, and as solidarity can be created by ensuring systems act in a fair and just manner, this change felt like a natural decision. Then, some categories were renamed -- \textit{Justice and fairness}, and \textit{Freedom and autonomy} were simplified to \textit{Justice} and \textit{Autonomy}, respectively. This was done to better aligned with common usage throughout the reviewed papers (e.g., \cite{Balagué_2021,Floridi_2018}, and the papers basing their principles on these). 

% Discuss split of principles (core and non-core)
Finally, after clusters had been created, these were again divided into two sets -- \emph{core} and \emph{instrumental} principles. This division was argued by \textcite{Canca_2020}, in order to separate core principles, that are \textquote{intrinsically valuable} (p. 19) from instrumental principles, \textquote{whose values are derived from their instrumental effect in protecting and promoting intrinsic values} (p. 20), in order to align principles for AI ethics, and thus responsible AI, with a \textquote{widely utilized set of core principles in applied ethics} (p. 19).

One key change was done to the division suggested by \textcite{Canca_2020}. \textit{Beneficence}, as suggested by \textcite{Canca_2020} to encapsulate both \textquote{avoiding
harm} and \textquote{doing good} (p. 19), was split into \textit{Beneficence} (doing good) and \textit{Non-maleficence} (avoiding harm). This has three benefits. First, it brings the division in line with the categories proposed by \textcite{Ryan_2021}, which are already used for the clustering mentioned above. Secondly, this aligns core principles of responsible AI with those currently used in applied ethics such as bioethics \parencite{Beauchamp_2001} and medicine \parencite{Gillon_2003,Gillon_1994}. Finally, this resonates with principles used by several of the reviewed papers (e.g., \cite{Balagué_2021,Floridi_2018,Jobin_2019,Nauck_2019}, and and the papers basing their principles on these), ensuring principles used within the field of responsible AI are placed in the group they belong.

\subsubsection{Core principles}
% Discuss core principles
% Why are they core?
% Why these principles?
% Where, outside of responsible AI, has this divide been used?

\paragraph{Autonomy}

\paragraph{Beneficence}

\paragraph{Non-maleficence}

\paragraph{Justice}


\subsubsection{Instrumental principles}
% Discuss a little about the variation of principles
% Depends on time, domain and concrete project

\paragraph{Transparency}
% Both system-, process- and technical

\paragraph{Accountability}

\paragraph{Privacy}

\paragraph{Trust}

\paragraph{Sustainability}

\paragraph{Data governance}

\paragraph{Laws and regulations}

\paragraph{Informed consent}

\paragraph{Predictability}

\paragraph{Quality benchmarking}

\paragraph{Interventions and co-design}

\paragraph{System performance}



% Then explanation of each principle, citing what the different sources have said, summarizing and possibly defining the principle in the context of RAI
% Include how the principles build upon each other / connections between principles
%   - I.e., how explainability is needed for the other principles to be applied
% Include also ways to enable the different principles, i.e. column "How to enable principles"

% Finally, discuss principles used by sources but not included here, as well as the reason why it was not included

% Possibly include some generic "How to enable principles" advice that apply to multiple principles
%   - E.g. data provenance (Werder K., Ramesh B., Zhang R.S.)

\subsection{RQ2 -- Antecedents for responsible AI}
\label{sec:results-rq2:antecedents}

\subsection{RQ3 -- Business advantages of responsible AI}
\label{sec:results-rq3:advantages}
% Academic stuff

% Outside of academia... (see Snowballing sources)


\subsection{Alternative terms for responsible AI}
\label{sec:results-alernative-terms}
% A comparison of the different terms for responsible AI I have seen throughout the review, and how they compare to each other.
% Use as base for future research -- a complete taxonomy of the field, establishing common and standardized terms
% Possibly a comparison of SCOPUS hits for the given terms, to show their popularity in comparison to each other

% \subsection{Challenges with responsible AI}
\subsection{Criticisms of responsible AI}
\label{sec:results-criticism}
% What challenges / barriers have the review shown?
% I.e., lack of implementation guides / most guidelines are very general and vague (maybe a "how to implement RAI" subsection?)
%   - Are also found in general ethics: https://www.scopus.com/record/display.uri?eid=2-s2.0-0025411067&origin=resultslist&sort=cp-f&src=s&st1=autonomy+AND+beneficence+AND+justice&nlo=&nlr=&nls=&sid=4734d518162d88ad8f175bc2a82e4e4f&sot=b&sdt=b&sl=41&s=ALL%28autonomy+AND+beneficence+AND+justice%29&relpos=9&citeCnt=324&searchTerm=
% "Ethics washing"
% Lack of quantitative research