\label{sec:Definitions}
% Definitions (both from review and thought-up myself)
Although theoretical and philosophical definitions fall slightly outside of the intended scope of this paper, it is necessary for a good understanding of responsible artificial intelligence to look at underlying terms and ensure clearly defined definitions related to the field. While many of the reviewed papers contain interesting and well-thought-out definitions, most of them wary significantly. There is thus a need to unify the definitions found in the field. To do so, this paper use the definitions found during the review, as well as some secondary material, to create classical definitions \parencite[p. 36]{Seppälä_2014} of the terms \textit{artificial intelligence}, \textit{artificial intelligence system} and \textit{responsible artificial intelligence}.


\subsubsection{Artificial intelligence}
\label{sec:definition-ai}
Not all the reviewed papers define the term artificial intelligence, and the definitions that are used differ in both wording and inclusion. Some similarities exist, however. Common among the definitions given by the reviewed papers is the notion that artificial intelligence technology is based on computing and software, e.g., \textquote{...algorithm-driven computing technology...} \parencite[p. 1]{Siala_2022}, \textquote{...computer systems...} \parencite[p. 130]{Brand_2022}, \textquote{A (computational) technology...} \parencite[p. 2]{Dignum_2021}, \textquote{Autonomous or intelligent software...} \parencite[p. 1]{Havrda_2020}, \textquote{...techniques and approaches of computer science...} \parencite[p. 3]{Liu_2021}, and \textquote{Machine-based systems...} \parencite[p. 1]{Lukkien_2021}. This largely aligns with the original idea of artificial intelligence, which was based on \textquote{a shared vision that computers can be made to perform intelligent tasks} \parencite[p. 87]{Moor_2006}.

Outside of this, however, the definitions differ. For instance, \textcite[p. 258]{Mikalef_2022} builds on \textcite{Mikalef_2021_notreview} and define AI as \textquote{the ability of a system to identify, interpret, make inferences, and learn from data to achieve predetermined organisational and societal goals,} thus adopting a definition removed from technology but based on learning. The notion of learning is repeated by \textcite[p. 2]{Dignum_2021}, who defines AI as \textquote{A (computational) technology that is able to infer patterns and possibly draw conclusions from data.} Her definition differs from that of \citeauthor{Mikalef_2022} in that she focuses on the technology, rather than the system, and she does not include the notion of the system's goals.

Focusing strongly on the outcome and technological side of the technology, \textcite[p. 130-131]{Brand_2022} bases his definition on the Oxford dictionary definition of AI, defining it as \textquote{the theory and development of computer systems able to perform tasks normally requiring human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages.} In a similar vein, \textcite[p. 1]{Havrda_2020} adopts the broad definition of AI given by \textcite{IEEE_vision} as \textquote{autonomous or intelligent software when installed into other software and/or hardware systems that are able to exercise independent reasoning, decision-making, intention forming, and motivating skills according to self-defined principles.}

Finally, several of the included papers focus on an ability of simulating humans. \textcite[p. 3-4]{Liu_2021} defines AI as \textquote{A broad range of techniques and approaches of computer science to simulate human intelligence in machines that are programmed for thinking like humans and mimic human behaviours, capable of performing tasks.} Similarly, \textcite[p. 3]{vanBruxvoort_2021} adopt the definition given by \textcite{Shubhendu_2013}, and define AI as
\begin{displayquote}
    the study of ideas to bring into being machines that respond to stimulation consistent with traditional responses from humans, given the human capacity for contemplation, judgment and intention. Each such machine should engage in critical appraisal and selection of differing opinions within itself.
\end{displayquote}

This paper bases its definition of artificial intelligence on the work done by \textcite[p.~1]{Siala_2022}, who define it as \textquote{[A]n algorithm-driven computing technology, [...] programmed to self-learn from data and make intelligent predictions and real-time decisions through the use of artificial neural networks, machine learning, robotic process automation, and data mining.} This describes the goals of AI (\textquote{to self-learn from data and make intelligent predictions and real-time decisions}), but includes information about how it should be implemented, which limits its use. Removing the implementation details, this paper adapts the work of \textcite{Siala_2022} and define \textit{artificial intelligence} as
\begin{displayquote}
    An algorithm-driven computing technology, programmed to self-learn from data and make intelligent predictions and real-time decisions.
\end{displayquote}


This definition of artificial intelligence covers several parts of the above-mentioned definitions. The notion of learning from data, as put forth by \textcite{Mikalef_2022} is explicitly covered. Similarly, the definition used by \textcite{Dignum_2021} is fully covered, as this paper's definition is based on technology, learns from data and explicitly draws conclusions based on it.

Due to the spread of definitions used by the reviewed papers, adopting a definition from one of them will naturally lead to it differing from others. This definition differs from \textcite{Liu_2021,vanBruxvoort_2021} in that it does not require the AI to be able to simulate human intelligence, nor must it have a capacity for contemplation, judgement or intention. Although this paper's definition is less strict than theirs, this brings it more in line with the current reality of AI, as systems able to simulate human intelligence are still more science fiction than reality \parencite{Chen_2020}. Similarly, this paper's definition does not mention any specific tasks it should be able to do, which differs from the definitions of \textcite{Brand_2022,Havrda_2020}, but ensures that the paper's definition is applicable to a wider range of systems than theirs.

The rest of this paper will be based on this definition.


\subsubsection{Artificial intelligence system}
% - AI system
%       "We take a socio-technical perspective, i.e., view the whole system of the algorithm as a technical component implemented in a technical infrastructure and an organisational structure accompanied by associated rules and regulations" (van Bruxvoort and van Keulen)
% - Lifecycle socio-technical system
% See Fjeld
Definitions of AI systems are sparse within the reviewed literature, although some attempts are made. \textcite{Dignum_2021} bases her definition of an AI system directly on the definition of AI, and defines it as 
\begin{displayquote}
    A software system (possibly embedded in hardware) designed by humans that, given a complex goal, is able to take a decision based on a process of perception, interpretation and reasoning based on data collected about the environment and that meets the properties of: 
    \begin{itemize}
        \item autonomy, meaning that the system is able to deliberate and act with the intent of reaching some task-specific goal without external control 
        \item adaptability, meaning that the system is able to sense its environment and update its behaviour to changes in the environment 
        \item interactivity, meaning that the system acts in a physical or digital dimension where people and other systems coexist. \parencite[p.~2]{Dignum_2021}
    \end{itemize}
\end{displayquote}

Conversely, \textcite[p.~8]{Merhi_2022} looks at what an AI system cannot do, and defines them as \textquote{robots and machines that have a limited ability and lack the intelligence that a human has to make a decision,} while \textcite[p.~2]{vanBruxvoort_2021} adopts a \textquote{socio-technical perspective} and \textquote{view the whole system of the algorithm as a technical component implemented in a technical infrastructure and an organisational structure accompanied by associated rules and regulations.}

This paper adopts the definition of AI systems as given by \textcite{Taddy_2018_AIsystem}. He argues that AI systems consist of three pillars that are required for the system to work -- a domain structure, data generation and machine learning routines. The domain structure is where the problem an AI system should solve is split into separate parts, that are manageable for simpler machine learning routines. This step requires domain knowledge and business expertise, as the problem must be broken down without inferring with the system's ability to solve it.

The data generation stage is where the AI system receives the data it needs to learn. According to \textcite[p.~4]{Taddy_2018_AIsystem}, AI systems \textquote{require an active strategy to keep a steady stream of new and useful information flowing into the composite learning algorithms.} This stage thus handles all data flow, including collecting it from its own processes.

The final stage, the machine learning routines, take the data generated from the data generation and uses it to learn to solve the broken-down problem provided by the domain structure \parencite{Taddy_2018_AIsystem}. This step is therefore what this paper defined as \textit{artificial intelligence}, as it learns from the data it is supplied and makes predictions and decisions.

The difference between AI and AI systems is thus that an AI system incorporates AI in a wider system. Whereas AI by itself passively learn from data and make predictions, AI systems collect data, and use this data with AI to make decisions suitable for the domain they operate in. Where AI is only able to passively learn what is given to them, AI systems are able to operate on their own, making decisions and predictions based on the domain they operate in and the decisions they are given.

To summarize, this paper defines an \textit{artificial intelligence system} as 
\begin{displayquote}
    A technology system that uses AI to make decisions and predictions that are suitable for the domain the system operates in, given the inputs it is given.
\end{displayquote}


\subsubsection{Responsible artificial intelligence}
\label{sec:definition-responsibleAI}
% As the benefits of AI are widely discussed, we will consider AI systems to be the default (i.e., what is compared against), so any discussed business advantages are of the responsible part, not the AI part
Following the previous two subsections, the only thing that remains in order to understand how to develop responsible AI is a proper definition of the term. The definitions of responsible AI used by the reviewed papers vary slightly. For instance, \textcite[p. 6]{Doorn_2021} defines responsible AI simply as AI that is \textquote{consistent with important ethical values,} whereas \textcite[p. 4964]{WangY_2020} define it as a human-centered governance framework, used to \textquote{harness, deploy, evaluate, and monitor AI machines to create new opportunities for better service provision.} In a similar vein, \textcite[p. 58-59]{Papagiannidis_2022} get their definition from \textcite{Singapore_framework}, who defines responsible AI as \textquote{the process of designing, developing, and deploying artificial intelligence with the purpose of enabling individuals and organisations while also having a fair effect on customers and society.} % Add Dignum 2019

Several of the reviewed papers use a set of principles as the core of their definition (e.g., \cite{WangW_2021,Cheng_2021}). For example, \textcite[p. 83]{BarredoArrieta_2020} define responsible AI as \textquote{a series of AI principles to be necessarily met when deploying AI in real applications.} In a similar fashion, \textcite[p. 258]{Mikalef_2022} builds on \textcite{Accenture_AIservices}, and define responsible AI as \textquote{a set of principles that ensure ethical, transparent, and accountable use of AI technologies.} Such principles typically make up the core of tools used to achieve responsible AI, and will be further studies later in \autoref{sec:results-rq1}. However, other tools for achieving the goals of responsible AI exist \parencite{Werder_2022}, and calls have been made for moving away from principles in the pursuit of responsibility \parencite{Henriksen_2021}.

Instead, inspiration for a definition can be found in dictionaries. Cambridge Dictionary \parencite{dictionary_responsible} has, among others, the following definition for the word \textit{responsible}: \textquote{having good judgment and the ability to act correctly and make decisions on your own.} Using this definition as foundation, it is clear that a responsible AI system must have an idea of what constitutes acting in a "correct" way, and do so to the best of its ability. This leaves the act of concluding what constitutes "correct" acting. In the reviewed papers, this is largely done by a set of principles, which will be further discussed in \autoref{sec:results-rq1}. The notion of what is a "correct" act, however, can vary between different technical systems \parencite{Hagendorff_2020}, as well as different cultures and background \parencite{Ford_1994}. Although some attempts have been made (e.g. \cite{Jobin_2019,Hagendorff_2020}), no universally agreed-upon set of principles exist.

In order to create a globally acceptable definition of responsible AI, this paper instead bases its definition of responsible AI on two views of applied ethics -- a utilitarian view, which simplifies a "correct" act to one that leads to maximum global utility \parencite{Lang_2004}, i.e., the largest possible amount of "good" for the largest possible amount of people, and a negative utilitarian view, which argues that a "correct" act is the one that leads to the least global suffering \parencite{Gandjour_2003_negativeutilitarianism}.  Combining these two views lead to defining \textit{responsible artificial intelligence} as
\begin{displayquote}
    An AI system designed, developed and used in an ethical way, to maximize global utility and minimize global harm.
\end{displayquote}

% Unused:
% This paper also adopts the notion of \parencite{Trocin_2021}, who suggest that a key aspect of responsible AI is its ability to reduce ethical issues.
% Definition: An AI system designed, developed and used in an ethical and accountable way, to maximize global utility and mitigate or eliminate ethical issues of AI.

As will be further discussed in \autoref{sec:results-rq1}, maximizing utility and minimizing harm are two similar, but not identical, goals. The goal of both is the same, however, in that "correct" actions are those that focus on "the greater good"

This definition is largely in line with the definition used by \textcite{Doorn_2021}, as both utilitarianism and negative utilitarianism are established ethical principles, and AI systems that follows these thus act consistent with ethical values. Similarly, if a service provides utility, then creating \textquote{new opportunities for better service provision} can be considered a way of increasing global utility, thus aligning this definition with that used by \textcite{WangY_2020}. The same, naturally, holds if the original system reduces harm. By acting fair, an AI system can reduce harm in the form of discrimination, and by enabling individuals, the system increases utility. This definition is, thus, also in line with that used by \textcite{Papagiannidis_2022}.

The definition differs from all those based on principles, as it also approves of AI systems acting responsibly based on other methods. However, ethical principles still make up the core of current methods for developing responsible systems. This paper therefore considers ethical principles as criteria for responsibility, and use them as the core of the implementation of responsibility, even for responsible AI systems following this definition.

It is important to note that throughout this paper, responsible AI will be used in contrast to regular AI system. As such, any antecedents, as discussed in \autoref{sec:results-rq2:antecedents}, are antecedents for adopting responsible principles, i.e., converting existing AI systems to be responsible, rather than antecedents for implementing AI solutions in the first place. The same is true for business advantages discussed in \autoref{sec:results-rq3:advantages}.