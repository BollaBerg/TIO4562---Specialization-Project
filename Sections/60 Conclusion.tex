\section{Conclusion}
\label{sec:Conclusion}

This paper looked at the current state of responsible AI research, by conducting a systematic literature review. The review resulted in a set of four core principles -- Autonomy, Beneficence, Non-maleficence and Justice -- that create responsible value by themselves, and seven instrumental principles -- Transparency, Accountability, Trust, Sustainability, Privacy and Others -- that create responsible value by facilitating for and supporting the core values. Additionally, the reviewed literature included three clusters of antecedents for responsible AI, as well as three clusters of business advantages that can be gained by adopting responsible AI practices.

These findings were used to create a project-level framework for responsible AI development, the EPNIS framework, designed to bridge the gap between abstract ethical principles and actual AI development. This framework is compared to existing frameworks for responsible AI, to show how it fits into the ecosystem of responsible AI development. Finally, the findings are used to point out future research that is needed within the field of responsible AI.
