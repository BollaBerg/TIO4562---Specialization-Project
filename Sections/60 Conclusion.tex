\section{Conclusion}
\label{sec:Conclusion}
\todo[inline]{Very temporary}


%%% Future work %%%
\subsection{Further work}
% A complete taxonomy of the field of AI ethics (all alternative terms for responsible AI)
% Obviously rewrite
This paper is focused on responsible AI. While alternative terms for responsible AI are mentioned and briefly discussed in \autoref{sec:results-alernative-terms}, delving too deep into the many, somewhat overlapping, terms for topics related to responsible AI is outside of the scope for this paper. To unify this wide range of terms, there is a need for an ontology or 
\todo{Should I focus on one of those? I am not fully clear on the difference}
taxonomy of the field. Ontologies are "representation vocabularies", capturing the conceptualizations underlying terms \parencite{Chandrasekaran_1999} whereas taxonomies "help humans classify objects according to similarities and differences" \parencite{Kundisch_2022}. Creating an ontology or taxonomy is thus a method to formally create a unifying definition of terms \parencite{Uschold_1996}, and would help to harmonize the wide usage of different terms within the field of AI ethics. Although AI has been used to aid ontology creation \parencite{Stumme_2001} and taxonomies have been created for other fields of AI, including sub-fields of AI ethics such as explainable AI \parencite{BarredoArrieta_2020}, as well as specific uses of AI \parencite{Gunn_2009,Ã–ren_1994,Fong_2003}, there is a lack of a unifying ontology or taxonomy, and thus a lack of common, agreed-upon definitions, within responsible AI or the wider field of AI ethics. % Something to conclude how it would help?


% Connections between the field of ethics (i.e., non-AI ethics, ethical theory and philosophy) and responsible AI?

% Consider ways to democratically create frameworks / guidelines. Create guidelines anchored in the general public in a democratic way (Gianni R., Lehtinen S., Nieminen M.)