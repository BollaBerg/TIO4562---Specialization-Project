\section{Data extraction example}
\label{app:Coding-example}

\begin{ThreePartTable}
\begin{TableNotes}
\tiny
\item [*] No data in this paper.
\end{TableNotes}

\begin{longtable}{P{0.2\textwidth}p{0.75\textwidth}}
    \caption[Example of data extraction applied to \textcite{Liu_2021}]{Example of data extraction applied to \textcite{Liu_2021}. For a description of each column, see \autoref{tab:extraction-columns}.}
    \label{tab:coding-example} \\
    \toprule
    \textbf{Column} & \textbf{Data} \\
    \endfirsthead
    
    \toprule
    \textbf{Column} & \textbf{Data} \\
    \midrule
    \endhead

    \bottomrule
    \multicolumn{2}{r}{\footnotesize \textit{Continued on next page\dots}}
    \endfoot

    \bottomrule
    \insertTableNotes
    \endlastfoot

        \multicolumn{2}{l}{\textit{Metadata}} \\
        \midrule
        Author & Liu R., Gupta S., Patel P. \\
        
        Title & The Application of the Principles of Responsible AI on Social Media Marketing for Digital Health \\
        
        Source & Information Systems Frontiers \\
        
        Source rank & 1 \\
        
        Year & 2021 \\
        
        Abstract & Social media enables medical professionals and authorities to share, disseminate, monitor, and manage health-related information digitally through online communities such as Twitter and Facebook. Simultaneously, artificial intelligence (AI) powered social media offers digital capabilities for organizations to select, screen, detect and predict problems with possible solutions through digital health data. Both the patients and healthcare professionals have benefited from such improvements. However, arising ethical concerns related to the use of AI raised by stakeholders need scrutiny which could help organizations obtain trust, minimize privacy invasion, and eventually facilitate the responsible success of AI-enabled social media operations. This paper examines the impact of responsible AI on businesses using insights from analysis of 25 in-depth interviews of health care professionals. The exploratory analysis conducted revealed that abiding by the responsible AI principles can allow healthcare businesses to better take advantage of the improved effectiveness of their social media marketing initiatives with their users. The analysis is further used to offer research propositions and conclusions, and the contributions and limitations of the study have been discussed. © 2021, The Author(s). \\
        
        Methodology & Qualitative interviews \\
        & Conceptual framework \\
        
        Sample & 25 health care professionals (healthcare managers and employees) in China \\
        
        Context & China, healthcare \\
        
        Contribution & Found that following responsible AI principles improves the effectiveness of social media marketing initiatives of healthcare businesses  \\

        \midrule
        \multicolumn{2}{l}{\textit{Key concept definitions}} \\
        \midrule
        AI & "A broad range of techniques and approaches of computer science to simulate human intelligence in machines that are programmed for thinking like humans and mimic human behaviours, capable of performing tasks" (p.3-4) \\\\
        
        Responsible AI & "Seeks to support the design, implementation, and use of ethical, transparent, and accountable AI solutions, aiming at reducing biases, facilitating fairness, equality, interpretability, and explainability (Trocin et al., 2021)" (p.3) \\\\
        & "Eitel-Porter (2021) defined the term as the practice of using AI with good intention, to empower employees and businesses and create a fair environment for customers and society, ultimately enabling organizations to generate trust and bring AI deployments to scale" (p.3) \\\\
        & "Taylor et al. (2018) regarded responsible AI as an umbrella term, which investigates legal, ethical, and moral viewpoints of autonomous algorithms or applications of AI that may be crucial to safety or may impact people’s lives in a disruptive way" (p.3) \\\\

        AI ethics & \tnote{*} \\
        
        Synonyms & "Responsible AI has been used interchangeably with ethical AI or the responsible use of AI." (p.3) \\
        
        AI system & \tnote{*} \\

        \midrule
        \multicolumn{2}{l}{\textit{Research questions}} \\
        \midrule
        Principles & From combining Clarke (2019), Microsoft AI (2020) and Floridi et al. (2018):\\
        & - Fairness \\
        & "Should not lead to discriminatory influences on humans associated with race, ethnic origin, religion, gender, sexual orientation, disability or other situations (Benjamins et al., 2019)" (p.14) \\\\
        & - Inclusiveness \\
        & - Reliability and safety \\
        & - Transparency \\
        & - Privacy and security \\
        & - Beneficence \\
        & - Non-maleficence \\
        & - Autonomy \\\\
        
        Antecedents & \tnote{*} \\\\

        Outcomes & Transparency: \\
        & - "Maintain the citizen’s rights to be informed" (p.21) \\\\
        & Fairness: \\
        & - "Increase users’ willingness to engage in the technology" (p.20) \\\\
        & Reliability and safety: \\
        & - "Users are more likely to perceive the usefulness of the technology to be willing to participate in it." (p.21) \\\\
        & Beneficence: \\
        & - "If users’ realization of the usefulness of responsible AI for health management increased, the acceptance of the technology would soon improve" (p.21) \\\\
        & Autonomy: \\
        & - Increase "users’ acceptability and intention to use the technology" (p.21) \\\\
        & "How well ethics are treated will ultimately decide how much people will embrace technology in the future" (p.21) \\\\

        Business advantages & "Companies might overlook the financial rewards of responsible AI and treat it as the sole way to avoid risks (Cheng et al., 2021)." (p.2) \\\\
        & Privacy and security: \\
        & - "A high level of good credibility and corporate reputation" (p.21) \\\\
        & Helps to "sustain a long-term relationship consumers" (p.22) \\
        & "It is believed that investing in social values based on trust, mutuality, and respect could enable long-term organizational benefits such as corporate well-being and innovativeness (Widén-Wulff \& Ginman, 2004)." (p.22) \\\\
        
        Barriers & "The attempts of these principles to translate into AI practices is still in their infancy (Benjamins, 2020; Cheng et al., 2021; Scantamburlo et al., 2020)" (p.2) \\
        & "It seems to be difficult to apply [responsible AI] to the practical hierarchy or to apply it to industries broadly." (p.4) \\
        & "Most responsible AI guidelines are useful and can help shape policy but are not easily enforceable" (p.4) \\\\
        
        Facilitators & \tnote{*} \\\\
        
        Enabling & Fairness: \\
        & - "Pay close attention to less privileged groups" (p.20) \\\\
        & Inclusiveness: \\
        & - "Involve more diverse audiences, respect their distinctive characteristics, and encourage active participation." (p.20) \\\\
        & Transparency: \\
        & - Make AI systems "relatively transparent" (p.20) \\\\
        & Autonomy: \\
        & - Different people (both across ages and the same age) may have different limits for how much assistance they want from an AI before they feel like they are losing autonomy \\
        & - AI systems must therefore adapt to each person \\\\
        & Privacy and security: \\
        & - "Seek strict privacy protection" (p.21) \\\\        
        & To sustain long-term relationships, a company should "concentrate on building trust, collecting, and ethically processing the data" (p.22) \\

        \midrule
        \multicolumn{2}{l}{\textit{Added after initial test}} \\
        \midrule
        Cases & "An artificially intelligent chatbot on a mobile app was created to give British people diagnostic advice on common ailments without human interaction (Olson, 2018)" (p.2) \\\\
        
        Other relevant data & "Many common pitfalls raise risks for an organization: rushed development, a lack of technical understanding, improper quality assurance, use of AI outside the original context, improper blends of data, and reluctance by employees to raise concerns (Eitel-Porter, 2021)" (p.4) \\\\
        & "Existing approaches to the implementation of ethical reasoning can be divided into three main categories: \\
        & - Top-down approaches are to implement a given ethical theory and apply it to a particular case; \\
        & - bottom-up approaches are to aggregate sufficient observations of similar situations into a decision and infer general rule from these independent cases; \\
        & - hybrid approaches combine the benefits of bottom-up and top-down approaches in support of a careful moral reflection (Singer, 2020)" (p.4) \\\\
        & "Microsoft has launched the Office of Responsible AI (ORA) and the AI, Ethics, and Effects in Engineering and Research (Aether) Committee to put responsible AI principles into practice (Microsoft AI, 2020). " (p.5) \\\\
        & "The technology acceptance model (TAM) [...] assumes that an individuals’ technology acceptance is determined by two major factors: perceived usefulness and perceived ease of use (King \& He, 2006)." (p.11) \\\\
        & "Trust is the most crucial antecedent and motivation for consumers’ willingness to share (Zaheer \& Trkman, 2017)." (p.22) \\

        \midrule
        \multicolumn{2}{l}{\textit{Own summary}} \\
        \midrule
        Summary & Combines three sources of principles to create their own set, and contains significant data / opinions on what the principles (and responsible AI in general) can lead to (mostly - increased trust). \\
\end{longtable}
\end{ThreePartTable}